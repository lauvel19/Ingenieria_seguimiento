import re
from typing import List, Tuple, Optional


class ImprovedReasoning:

    @staticmethod
    def deductive_reasoning(premise1: str, premise2: str) -> str:
        """
        Razonamiento deductivo mejorado que maneja m√∫ltiples formatos de premisas
        """
        try:
            # Verificar premisas vac√≠as
            if not premise1.strip() or not premise2.strip():
                return "‚ùå Error: Ambas premisas deben contener texto v√°lido"

            # Normalizaci√≥n m√°s agresiva
            p1 = premise1.lower().replace(".", "").replace(",", "").strip()
            p2 = premise2.lower().replace(".", "").replace(",", "").strip()

            # Patrones m√°s flexibles para detectar premisas
            def extract_logical_elements(premise):
                """Extrae sujeto y predicado de una premisa con mayor flexibilidad"""

                # Patr√≥n 1: "Todos los X son Y"
                match = re.search(r"todos?\s+los?\s+(.+?)\s+son\s+(.+)", premise)
                if match:
                    return ("todos", match.group(1).strip(), match.group(2).strip())

                # Patr√≥n 2: "Todo X es Y"
                match = re.search(r"todo\s+(.+?)\s+es\s+(.+)", premise)
                if match:
                    return ("todos", match.group(1).strip(), match.group(2).strip())

                # Patr√≥n 3: "Los X son Y"
                match = re.search(r"los?\s+(.+?)\s+son\s+(.+)", premise)
                if match:
                    return ("los", match.group(1).strip(), match.group(2).strip())

                # Patr√≥n 4: "X es Y" (para casos espec√≠ficos)
                match = re.search(r"(.+?)\s+es\s+(.+)", premise)
                if match:
                    subject = match.group(1).strip()
                    predicate = match.group(2).strip()
                    # Verificar si es un caso espec√≠fico (nombre propio o art√≠culo definido)
                    if any(word in subject for word in ["el ", "la ", "un ", "una "]) or subject[0].isupper():
                        return ("es", subject, predicate)

                # Patr√≥n 5: "Si X entonces Y"
                match = re.search(r"si\s+(.+?)\s+entonces\s+(.+)", premise)
                if match:
                    return ("si-entonces", match.group(1).strip(), match.group(2).strip())

                # Patr√≥n 6: "Ning√∫n X es Y"
                match = re.search(r"ning√∫n\s+(.+?)\s+es\s+(.+)", premise)
                if match:
                    return ("ning√∫n", match.group(1).strip(), match.group(2).strip())

                # Patr√≥n 7: "Algunos X son Y"
                match = re.search(r"algunos?\s+(.+?)\s+son\s+(.+)", premise)
                if match:
                    return ("algunos", match.group(1).strip(), match.group(2).strip())

                return None

            # Extraer elementos de ambas premisas
            elements1 = extract_logical_elements(p1)
            elements2 = extract_logical_elements(p2)

            if not elements1 or not elements2:
                return (f"üîç **Formato no reconocido.** Intenta con:\n\n"
                        f"**Formatos v√°lidos:**\n"
                        f"‚Ä¢ 'Todos los humanos son mortales'\n"
                        f"‚Ä¢ 'S√≥crates es humano'\n"
                        f"‚Ä¢ 'Los perros son animales'\n"
                        f"‚Ä¢ 'Si llueve entonces est√° mojado'\n"
                        f"‚Ä¢ 'Ning√∫n reptil es mam√≠fero'\n\n"
                        f"**Lo que recib√≠:**\n"
                        f"‚Ä¢ Premisa 1: '{premise1}'\n"
                        f"‚Ä¢ Premisa 2: '{premise2}'")

            quantifier1, subj1, pred1 = elements1
            quantifier2, subj2, pred2 = elements2

            # Normalizar t√©rminos para comparaci√≥n (eliminar art√≠culos)
            def normalize_term(term):
                # Eliminar art√≠culos y espacios extra
                normalized = re.sub(r'^(el|la|los|las|un|una)\s+', '', term.strip())
                return normalized

            norm_subj1 = normalize_term(subj1)
            norm_pred1 = normalize_term(pred1)
            norm_subj2 = normalize_term(subj2)
            norm_pred2 = normalize_term(pred2)

            # L√≥gica de inferencia mejorada
            conclusion = None

            # Caso 1: Silogismo Barbara - Todos A son B, Todos B son C ‚Üí Todos A son C
            if (quantifier1 == "todos" and quantifier2 == "todos" and
                    (norm_pred1 == norm_subj2 or pred1 == subj2)):
                conclusion = f"‚úÖ **Conclusi√≥n v√°lida:** Todos los {subj1} son {pred2}"
                explanation = f"üìö **Tipo:** Silogismo categ√≥rico (Barbara)\nüîó **Conexi√≥n:** {pred1} = {subj2}"

            # Caso 2: Silogismo con caso espec√≠fico - Todos A son B, X es A ‚Üí X es B
            elif (quantifier1 == "todos" and quantifier2 == "es" and
                  (norm_subj2 in norm_subj1 or norm_subj1 in norm_subj2 or subj1 in subj2)):
                conclusion = f"‚úÖ **Conclusi√≥n v√°lida:** {subj2} es {pred1}"
                explanation = f"üìö **Tipo:** Silogismo con caso particular\nüîó **Conexi√≥n:** {subj2} pertenece a {subj1}"

            # Caso 3: Inverso - X es A, Todos A son B ‚Üí X es B
            elif (quantifier1 == "es" and quantifier2 == "todos" and
                  (norm_subj1 in norm_subj2 or norm_subj2 in norm_subj1 or subj2 in subj1)):
                conclusion = f"‚úÖ **Conclusi√≥n v√°lida:** {subj1} es {pred2}"
                explanation = f"üìö **Tipo:** Silogismo con caso particular\nüîó **Conexi√≥n:** {subj1} pertenece a {subj2}"

            # Caso 4: Modus Ponens - Si A entonces B, A ‚Üí B
            elif (quantifier1 == "si-entonces" and
                  (subj1 in p2 or any(word in subj1 for word in p2.split()))):
                conclusion = f"‚úÖ **Conclusi√≥n v√°lida:** {pred1}"
                explanation = f"üìö **Tipo:** Modus Ponens\nüîó **Se confirma:** {subj1}"

            # Caso 5: Conexi√≥n por predicado com√∫n
            elif (quantifier1 in ["todos", "los"] and quantifier2 in ["todos", "los"] and
                  (norm_pred1 == norm_pred2 or pred1 == pred2)):
                conclusion = f"‚úÖ **Conexi√≥n identificada:** Tanto {subj1} como {subj2} son {pred1}"
                explanation = f"üìö **Tipo:** Relaci√≥n por predicado com√∫n\nüîó **Caracter√≠stica compartida:** {pred1}"

            # Caso 6: Ning√∫n + Todos (Celarent)
            elif (quantifier1 == "ning√∫n" and quantifier2 == "todos" and
                  (norm_pred1 == norm_subj2 or pred1 == subj2)):
                conclusion = f"‚úÖ **Conclusi√≥n v√°lida:** Ning√∫n {subj2} es {subj1}"
                explanation = f"üìö **Tipo:** Silogismo categ√≥rico (Celarent)\nüîó **Conexi√≥n:** {pred1} = {subj2}"

            else:
                # Verificar si hay alguna relaci√≥n
                all_terms1 = {norm_subj1, norm_pred1, subj1, pred1}
                all_terms2 = {norm_subj2, norm_pred2, subj2, pred2}
                common_terms = all_terms1 & all_terms2

                if common_terms:
                    return (f"‚ö†Ô∏è **Relaci√≥n detectada pero no forma silogismo v√°lido**\n\n"
                            f"**T√©rminos en com√∫n:** {', '.join(common_terms)}\n\n"
                            f"**Premisas analizadas:**\n"
                            f"‚Ä¢ **Premisa 1:** {quantifier1} {subj1} ‚Üí {pred1}\n"
                            f"‚Ä¢ **Premisa 2:** {quantifier2} {subj2} ‚Üí {pred2}\n\n"
                            f"üí° **Sugerencia:** Reorganiza las premisas para crear una cadena l√≥gica clara.")
                else:
                    return (f"‚ùå **No hay conexi√≥n l√≥gica entre las premisas**\n\n"
                            f"**An√°lisis:**\n"
                            f"‚Ä¢ **Premisa 1:** {quantifier1} {subj1} ‚Üí {pred1}\n"
                            f"‚Ä¢ **Premisa 2:** {quantifier2} {subj2} ‚Üí {pred2}\n\n"
                            f"üí° **Para razonamiento deductivo v√°lido, necesitas:**\n"
                            f"‚Ä¢ Premisas que compartan t√©rminos comunes\n"
                            f"‚Ä¢ Una estructura l√≥gica clara (A‚ÜíB, B‚ÜíC)")

            return f"{conclusion}\n\n{explanation}"

        except Exception as e:
            return f"‚ùå Error al procesar: {str(e)}"

    @staticmethod
    def inductive_reasoning(observations: List[str]) -> str:
        """
        Razonamiento inductivo mejorado con mejor reconocimiento de patrones
        """
        try:
            # Filtrar observaciones vac√≠as
            cleaned_obs = [obs.strip() for obs in observations if obs.strip()]

            if len(cleaned_obs) < 2:
                return "‚ö†Ô∏è Se necesitan al menos 2 observaciones para identificar un patr√≥n"

            if len(cleaned_obs) < 3:
                return "‚ö†Ô∏è Con solo 2 observaciones la generalizaci√≥n es muy d√©bil. A√±ade m√°s observaciones para mayor confianza."

            # An√°lisis de patrones mejorado
            def extract_pattern_elements(observation):
                """Extrae componentes de una observaci√≥n"""
                obs_clean = observation.lower().strip()

                # Patrones de an√°lisis m√°s flexibles
                patterns = [
                    r"(.+?)\s+(es|son|est√°|est√°n|tiene|tienen|hace|hacen|puede|pueden)\s+(.+)",
                    r"(.+?)\s+(.+)"  # Patr√≥n m√°s general
                ]

                for pattern in patterns:
                    match = re.search(pattern, obs_clean)
                    if match:
                        if len(match.groups()) >= 3:
                            return {
                                "subject": match.group(1).strip(),
                                "verb": match.group(2).strip(),
                                "predicate": match.group(3).strip(),
                                "full": obs_clean
                            }
                        else:
                            # Dividir en dos partes
                            parts = obs_clean.split()
                            mid = len(parts) // 2
                            return {
                                "subject": " ".join(parts[:mid]),
                                "verb": "",
                                "predicate": " ".join(parts[mid:]),
                                "full": obs_clean
                            }

                return {"subject": "", "verb": "", "predicate": obs_clean, "full": obs_clean}

            # Extraer elementos de todas las observaciones
            elements = [extract_pattern_elements(obs) for obs in cleaned_obs]

            # Encontrar patrones comunes en sujetos
            subjects = [elem["subject"] for elem in elements if elem["subject"]]
            subject_pattern = None

            if subjects:
                # Buscar palabras comunes en sujetos
                subject_words = []
                for subj in subjects:
                    subject_words.extend(subj.split())

                # Encontrar la palabra m√°s frecuente que aparece en la mayor√≠a
                word_counts = {}
                for word in subject_words:
                    if len(word) > 2:  # Ignorar palabras muy cortas
                        word_counts[word] = word_counts.get(word, 0) + 1

                # Buscar palabra que aparezca en al menos la mitad de las observaciones
                for word, count in word_counts.items():
                    if count >= len(cleaned_obs) * 0.5:
                        subject_pattern = word
                        break

                # Si no encuentra patr√≥n espec√≠fico, inferir categor√≠a
                if not subject_pattern:
                    if any(word in " ".join(subjects) for word in ["perro", "gato", "animal"]):
                        subject_pattern = "animales"
                    elif any(word in " ".join(subjects) for word in ["p√°jaro", "ave", "cisne"]):
                        subject_pattern = "aves"
                    elif any(word in " ".join(subjects) for word in ["persona", "humano", "gente"]):
                        subject_pattern = "personas"
                    else:
                        subject_pattern = "elementos observados"

            # Encontrar patrones comunes en predicados
            predicates = [elem["predicate"] for elem in elements if elem["predicate"]]
            predicate_pattern = None

            if predicates:
                # Buscar palabras que aparezcan en la mayor√≠a de predicados
                predicate_words = []
                for pred in predicates:
                    predicate_words.extend(pred.split())

                common_predicate_words = []
                word_counts = {}
                for word in predicate_words:
                    if len(word) > 2:
                        word_counts[word] = word_counts.get(word, 0) + 1

                for word, count in word_counts.items():
                    if count >= len(cleaned_obs) * 0.6:  # Aparece en al menos 60% de observaciones
                        common_predicate_words.append(word)

                if common_predicate_words:
                    predicate_pattern = ", ".join(sorted(common_predicate_words))

            # Encontrar verbo com√∫n
            verbs = [elem["verb"] for elem in elements if elem["verb"]]
            verb_pattern = None
            if verbs:
                verb_counts = {}
                for verb in verbs:
                    verb_counts[verb] = verb_counts.get(verb, 0) + 1

                if verb_counts:
                    verb_pattern = max(verb_counts, key=verb_counts.get)

            # Generar conclusi√≥n inductiva
            confidence = min(len(cleaned_obs) * 15 + 10, 85)  # M√°ximo 85% de confianza

            if subject_pattern and predicate_pattern:
                if verb_pattern:
                    conclusion = f"üîç **Generalizaci√≥n inductiva** (Confianza: {confidence}%):\n"
                    conclusion += f"Los {subject_pattern} {verb_pattern} {predicate_pattern}"
                else:
                    conclusion = f"üîç **Patr√≥n identificado** (Confianza: {confidence}%):\n"
                    conclusion += f"Los {subject_pattern} tienen la caracter√≠stica: {predicate_pattern}"
            elif subject_pattern:
                conclusion = f"üîç **Patr√≥n en sujetos identificado** (Confianza: {confidence}%)\n"
                conclusion += f"Patr√≥n detectado en: {subject_pattern}"
            else:
                conclusion = f"‚ö†Ô∏è **Patr√≥n d√©bil** identificado en {len(cleaned_obs)} observaciones"

            # A√±adir advertencias y sugerencias
            warning = ("\n\n‚ö†Ô∏è **Importante sobre razonamiento inductivo:**\n"
                       f"‚Ä¢ Las generalizaciones NO garantizan certeza\n"
                       f"‚Ä¢ Una excepci√≥n puede invalidar la regla\n"
                       f"‚Ä¢ Basado en {len(cleaned_obs)} observaci√≥n{'es' if len(cleaned_obs) > 1 else ''}\n")

            if len(cleaned_obs) < 5:
                warning += f"‚Ä¢ üí° **Sugerencia:** A√±ade m√°s observaciones para mayor confianza\n"

            if confidence < 50:
                warning += f"‚Ä¢ ‚ö†Ô∏è **Confianza baja:** El patr√≥n necesita m√°s evidencia\n"

            return conclusion + warning

        except Exception as e:
            return f"‚ùå Error al procesar observaciones: {str(e)}"

    @staticmethod
    def analyze_argument_strength(premise1: str, premise2: str, conclusion: str) -> str:
        """Analiza la fortaleza de un argumento completo"""
        try:
            # Verificar si es deductivo v√°lido
            deductive_result = ImprovedReasoning.deductive_reasoning(premise1, premise2)

            if "Conclusi√≥n v√°lida" in deductive_result:
                return f"üí™ **Argumento DEDUCTIVO V√ÅLIDO**\n{deductive_result}\n\n‚úÖ La conclusi√≥n se sigue necesariamente de las premisas."
            else:
                return f"‚ö†Ô∏è **Argumento DEDUCTIVO INV√ÅLIDO**\n{deductive_result}\n\n‚ùå La conclusi√≥n no se sigue necesariamente de las premisas."

        except Exception as e:
            return f"‚ùå Error en el an√°lisis: {str(e)}"